{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcq6dWzy1ZR0"
      },
      "source": [
        "# Payment Date Prediction "
      ],
      "id": "wcq6dWzy1ZR0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2778654e"
      },
      "source": [
        "\n",
        "### Importing related Libraries "
      ],
      "id": "2778654e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "304c9e38"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "import sklearn.metrics as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
      ],
      "id": "304c9e38"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8724f5ee"
      },
      "source": [
        "### Store the dataset into the Dataframe\n"
      ],
      "id": "8724f5ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKPKLMngUhfG"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "vKPKLMngUhfG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "415db50a"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv (r'/content/drive/MyDrive/dataset.csv')   \n",
        "pd.options.display.max_rows = 99999\n",
        "df.head(10)"
      ],
      "id": "415db50a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42e37f05"
      },
      "source": [
        "### Check the shape of the dataframe\n"
      ],
      "id": "42e37f05"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27cc0907"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ],
      "id": "27cc0907"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b68c955d"
      },
      "source": [
        "### Check the Detail information of the dataframe"
      ],
      "id": "b68c955d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e092ec9e"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ],
      "id": "e092ec9e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "112f2d0e"
      },
      "source": [
        "### Display All the column names"
      ],
      "id": "112f2d0e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1416e2fd"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ],
      "id": "1416e2fd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d465ed7a"
      },
      "source": [
        " **Describe the entire dataset**\n",
        "\n",
        "\n"
      ],
      "id": "d465ed7a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25f65e1b"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ],
      "id": "25f65e1b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f2c8d02"
      },
      "source": [
        "# Data Cleaning\n",
        "\n",
        "- Show top 5 records from the dataset"
      ],
      "id": "0f2c8d02"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f876212"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ],
      "id": "8f876212"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92b044e4"
      },
      "source": [
        "### Display the Null values percentage against every columns (compare to the total number of records)\n",
        "\n",
        "- Output expected : area_business - 100% null, clear_data = 20% null, invoice_id = 0.12% null"
      ],
      "id": "92b044e4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24c7b13d"
      },
      "outputs": [],
      "source": [
        "percent_missing = df.isnull().sum() * 100 / len(df)\n",
        "missing_value_df = pd.DataFrame({'percent_missing': percent_missing})\n",
        "print(missing_value_df)"
      ],
      "id": "24c7b13d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c46a98b"
      },
      "source": [
        "### Display Invoice_id and Doc_Id\n",
        "\n",
        "- Note - Many of the would have same invoice_id and doc_id\n"
      ],
      "id": "2c46a98b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "038f24bb"
      },
      "outputs": [],
      "source": [
        "df.loc[:,[\"invoice_id\",\"doc_id\"]]"
      ],
      "id": "038f24bb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18cfe10a"
      },
      "source": [
        "#### Write a code to check - 'baseline_create_date',\"document_create_date\",'document_create_date.1' - these columns are almost same.\n",
        "\n",
        "- Please note, if they are same, we need to drop them later\n",
        "\n"
      ],
      "id": "18cfe10a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf5b40ff"
      },
      "outputs": [],
      "source": [
        "comparison_column = np.where(df[\"baseline_create_date\"] == df[\"document_create_date\"], True, False)\n",
        "print(comparison_column)"
      ],
      "id": "cf5b40ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33110576"
      },
      "source": [
        "#### Please check, Column 'posting_id' is constant columns or not\n"
      ],
      "id": "33110576"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecce2664"
      },
      "outputs": [],
      "source": [
        "print(df['posting_id'].head(5))"
      ],
      "id": "ecce2664"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5fb8daf"
      },
      "source": [
        "#### Please check 'isOpen' is a constant column and relevant column for this project or not"
      ],
      "id": "e5fb8daf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8db9956b"
      },
      "outputs": [],
      "source": [
        "print(df['isOpen'].head(5))"
      ],
      "id": "8db9956b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45a11a62"
      },
      "source": [
        "### Write the code to drop all the following columns from the dataframe\n",
        "\n",
        "- 'area_business'\n",
        "- \"posting_id\"\n",
        "- \"invoice_id\"\n",
        "- \"document_create_date\"\n",
        "- \"isOpen\"\n",
        "- 'document type' \n",
        "- 'document_create_date.1"
      ],
      "id": "45a11a62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "270d85d1"
      },
      "outputs": [],
      "source": [
        "df.drop(['area_business', 'posting_id', 'invoice_id', 'document_create_date', 'isOpen', 'document_create_date.1', 'document type'], axis=1, inplace=True)\n",
        "\n"
      ],
      "id": "270d85d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5LHAM2XVGnk"
      },
      "source": [
        "### Please check from the dataframe whether all the columns are removed or not "
      ],
      "id": "K5LHAM2XVGnk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef3f7d2b"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ],
      "id": "ef3f7d2b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bc052c7"
      },
      "source": [
        "### Show all the Duplicate rows from the dataframe"
      ],
      "id": "6bc052c7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ae3c7e4"
      },
      "outputs": [],
      "source": [
        "print(df.duplicated())"
      ],
      "id": "1ae3c7e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "464fab09"
      },
      "source": [
        "### Display the Number of Duplicate Rows"
      ],
      "id": "464fab09"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1ea2397"
      },
      "outputs": [],
      "source": [
        "print(df.duplicated().sum())\n"
      ],
      "id": "b1ea2397"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "827a6718"
      },
      "source": [
        "### Drop all the Duplicate Rows"
      ],
      "id": "827a6718"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d10151c"
      },
      "outputs": [],
      "source": [
        "df.drop_duplicates(inplace = True)\n",
        "print(df.count())"
      ],
      "id": "5d10151c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e5d1f9b"
      },
      "source": [
        "#### Now check for all duplicate rows now\n",
        "\n",
        "- Note - It must be 0 by now"
      ],
      "id": "7e5d1f9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9accc9fc"
      },
      "outputs": [],
      "source": [
        "print(df.duplicated().sum())\n"
      ],
      "id": "9accc9fc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0704898"
      },
      "source": [
        "### Check for the number of Rows and Columns in your dataset"
      ],
      "id": "d0704898"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "582748a8"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ],
      "id": "582748a8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4o9c5UodWRtl"
      },
      "source": [
        "### Find out the total count of null values in each columns"
      ],
      "id": "4o9c5UodWRtl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0612cb5"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ],
      "id": "b0612cb5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7abdb98b"
      },
      "source": [
        "#Data type Conversion "
      ],
      "id": "7abdb98b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPfSUSp-WpPj"
      },
      "source": [
        "### Please check the data type of each column of the dataframe"
      ],
      "id": "LPfSUSp-WpPj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "689c8592"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ],
      "id": "689c8592"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nsem0_3XzOt"
      },
      "source": [
        "### Check the datatype format of below columns\n",
        "\n",
        "- clear_date  \n",
        "- posting_date\n",
        "- due_in_date \n",
        "- baseline_create_date"
      ],
      "id": "0nsem0_3XzOt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yyODyW3X6pL"
      },
      "outputs": [],
      "source": [
        "print(df['clear_date'].head(0))\n",
        "print(df['posting_date'].head(0))\n",
        "print(df['due_in_date'].head(0))\n",
        "print(df['baseline_create_date'].head(0))"
      ],
      "id": "-yyODyW3X6pL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11cf9478"
      },
      "source": [
        "### converting date columns into date time formats\n",
        "\n",
        "- clear_date  \n",
        "- posting_date\n",
        "- due_in_date \n",
        "- baseline_create_date\n",
        "\n",
        "\n",
        "- **Note - You have to convert all these above columns into \"%Y%m%d\" format**"
      ],
      "id": "11cf9478"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a8c6c71"
      },
      "outputs": [],
      "source": [
        "df['clear_date']=pd.to_datetime(df['clear_date'],format='%d-%m-%y %H:%M')\n",
        "df['posting_date']=pd.to_datetime(df['posting_date'],format='%d-%m-%y')\n",
        "df['due_in_date']=pd.to_datetime(df['due_in_date'],format='%Y%m%d')\n",
        "df['baseline_create_date']=pd.to_datetime(df['baseline_create_date'],format='%Y%m%d')\n"
      ],
      "id": "9a8c6c71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7adq0wSIYSCS"
      },
      "source": [
        "### Please check the datatype of all the columns after conversion of the above 4 columns"
      ],
      "id": "7adq0wSIYSCS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fd028c61"
      },
      "outputs": [],
      "source": [
        "df['clear_date'].head(4)\n"
      ],
      "id": "fd028c61"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zM_OsP6CLJZj"
      },
      "outputs": [],
      "source": [
        "df['posting_date'].head(4)\n"
      ],
      "id": "zM_OsP6CLJZj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5uAKBW0LKkG"
      },
      "outputs": [],
      "source": [
        "df['due_in_date'].head(4)\n"
      ],
      "id": "P5uAKBW0LKkG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvKIy7nULLq9"
      },
      "outputs": [],
      "source": [
        "df['baseline_create_date'].head(4)"
      ],
      "id": "tvKIy7nULLq9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8c9882fa"
      },
      "source": [
        "#### the invoice_currency column contains two different categories, USD and CAD\n",
        "\n",
        "- Please do a count of each currency "
      ],
      "id": "8c9882fa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72085397"
      },
      "outputs": [],
      "source": [
        "df[\"invoice_currency\"].value_counts()"
      ],
      "id": "72085397"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cbe26ee"
      },
      "source": [
        "#### display the \"total_open_amount\" column value"
      ],
      "id": "6cbe26ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c49f2ab"
      },
      "outputs": [],
      "source": [
        "df['total_open_amount']"
      ],
      "id": "6c49f2ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df899966"
      },
      "source": [
        "### Convert all CAD into USD currency of \"total_open_amount\" column\n",
        "\n",
        "- 1 CAD = 0.7 USD\n",
        "- Create a new column i.e \"converted_usd\" and store USD and convered CAD to USD"
      ],
      "id": "df899966"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eb2f1c5"
      },
      "outputs": [],
      "source": [
        "temp = df.loc[df['invoice_currency'] == 'CAD']\n",
        "df['cad']=  0.7 * temp['total_open_amount'].fillna(0)\n",
        "df['cad']=df['cad'].fillna(0)\n",
        "\n",
        "temp1= df.loc[df['invoice_currency'] == 'USD']\n",
        "df['usd']=  1 * temp1['total_open_amount'] \n",
        "df['usd']=df['usd'].fillna(0)\n",
        "\n",
        "\n",
        "df['converted_usd']=df['usd']+df['cad']\n",
        "\n",
        "df.drop(['cad', 'usd'], axis=1, inplace=True)\n",
        "df.head(100)"
      ],
      "id": "8eb2f1c5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9f6ef1d"
      },
      "source": [
        "### Display the new \"converted_usd\" column values"
      ],
      "id": "f9f6ef1d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fc1a178"
      },
      "outputs": [],
      "source": [
        "df['converted_usd']"
      ],
      "id": "1fc1a178"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XLXX17kayuy"
      },
      "source": [
        "### Display year wise total number of record \n",
        "\n",
        "- Note -  use \"buisness_year\" column for this "
      ],
      "id": "6XLXX17kayuy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00c9f6ee"
      },
      "outputs": [],
      "source": [
        "df.sort_values(by='buisness_year',inplace=True) \n",
        "df"
      ],
      "id": "00c9f6ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05c35904"
      },
      "source": [
        "### Write the code to delete the following columns \n",
        "\n",
        "- 'invoice_currency'\n",
        "- 'total_open_amount', "
      ],
      "id": "05c35904"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ac28aa5"
      },
      "outputs": [],
      "source": [
        "df.drop(['invoice_currency', 'total_open_amount'], axis=1, inplace=True)\n"
      ],
      "id": "4ac28aa5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDBJ_Kvwc086"
      },
      "source": [
        "### Write a code to check the number of columns in dataframe"
      ],
      "id": "bDBJ_Kvwc086"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ea360a8c"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ],
      "id": "ea360a8c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8f63655"
      },
      "source": [
        "# Splitting the Dataset "
      ],
      "id": "b8f63655"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a00f749d"
      },
      "source": [
        "### Look for all columns containing null value\n",
        "\n",
        "- Note - Output expected is only one column "
      ],
      "id": "a00f749d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "148c801e"
      },
      "outputs": [],
      "source": [
        "df.isna().any()[lambda x: x]"
      ],
      "id": "148c801e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a094a290"
      },
      "source": [
        "#### Find out the number of null values from the column that you got from the above code"
      ],
      "id": "a094a290"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30bfb113"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ],
      "id": "30bfb113"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f6d939b"
      },
      "source": [
        "### On basis of the above column we are spliting data into dataset\n",
        "\n",
        "- First dataframe (refer that as maindata) only containing the rows, that have NO NULL data in that column ( This is going to be our train dataset ) \n",
        "- Second dataframe (refer that as nulldata) that contains the columns, that have Null data in that column ( This is going to be our test dataset ) "
      ],
      "id": "7f6d939b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8764c33"
      },
      "outputs": [],
      "source": [
        "train_data = df[df.clear_date.notnull()].reset_index()\n",
        "train_data.drop(columns=['index'],inplace=True)\n"
      ],
      "id": "c8764c33"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbZ7uisMjhUf"
      },
      "outputs": [],
      "source": [
        "test_data = df[df.clear_date.isnull()].reset_index()\n",
        "test_data.drop(columns=['index'],inplace=True)\n"
      ],
      "id": "tbZ7uisMjhUf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3P8riRBHd_r6"
      },
      "source": [
        "### Check the number of Rows and Columns for both the dataframes "
      ],
      "id": "3P8riRBHd_r6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0693a464"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ],
      "id": "0693a464"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7f86bc74"
      },
      "outputs": [],
      "source": [
        "test_data.info()"
      ],
      "id": "7f86bc74"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0747165d"
      },
      "source": [
        "### Display the 5 records from maindata and nulldata dataframes"
      ],
      "id": "0747165d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dec2ec36"
      },
      "outputs": [],
      "source": [
        "train_data.head(5)"
      ],
      "id": "dec2ec36"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eee2d68a"
      },
      "outputs": [],
      "source": [
        "test_data.head(5)"
      ],
      "id": "eee2d68a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24aa6746"
      },
      "source": [
        "## Considering the **maindata**"
      ],
      "id": "24aa6746"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f92c4aa7"
      },
      "source": [
        "#### Generate a new column \"Delay\" from the existing columns\n",
        "\n",
        "- Note - You are expected to create a new column 'Delay' from two existing columns, \"clear_date\" and \"due_in_date\" \n",
        "- Formula - Delay = clear_date - due_in_date"
      ],
      "id": "f92c4aa7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eeceb9c"
      },
      "outputs": [],
      "source": [
        "train_data['delay']=(train_data['clear_date']-train_data['due_in_date']).dt.days"
      ],
      "id": "8eeceb9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfAeiYXjiABQ"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ],
      "id": "kfAeiYXjiABQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVeA8dB-k3qI"
      },
      "outputs": [],
      "source": [
        "train_data.head(10)"
      ],
      "id": "yVeA8dB-k3qI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f482144e"
      },
      "source": [
        "### Generate a new column \"avgdelay\" from the existing columns\n",
        "\n",
        "- Note - You are expected to make a new column \"avgdelay\" by grouping \"name_customer\" column with reapect to mean of the \"Delay\" column.\n",
        "- This new column \"avg_delay\" is meant to store \"customer_name\" wise delay\n",
        "- groupby('name_customer')['Delay'].mean(numeric_only=False)\n",
        "- Display the new \"avg_delay\" column"
      ],
      "id": "f482144e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d18d2f8d"
      },
      "outputs": [],
      "source": [
        "ad =train_data.groupby('name_customer')['delay'].mean()\n",
        "ad\n",
        "\n"
      ],
      "id": "d18d2f8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64b995e8"
      },
      "source": [
        "You need to add the \"avg_delay\" column with the maindata, mapped with \"name_customer\" column\n",
        "\n",
        " - Note - You need to use map function to map the avgdelay with respect to \"name_customer\" column"
      ],
      "id": "64b995e8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1e1f3d9"
      },
      "outputs": [],
      "source": [
        "train_data['avg_delay'] = train_data['name_customer'].map(ad)\n",
        "train_data\n"
      ],
      "id": "e1e1f3d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d332525"
      },
      "source": [
        "### Observe that the \"avg_delay\" column is in days format. You need to change the format into seconds\n",
        "\n",
        "- Days_format :  17 days 00:00:00\n",
        "- Format in seconds : 1641600.0"
      ],
      "id": "1d332525"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d36RZUQySZbP"
      },
      "outputs": [],
      "source": [
        "ad= (train_data['avg_delay']*24*60*60)\n",
        "ad"
      ],
      "id": "d36RZUQySZbP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvgtHSsx_O-n"
      },
      "source": [
        "### Display the maindata dataframe "
      ],
      "id": "OvgtHSsx_O-n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97ca9c45"
      },
      "outputs": [],
      "source": [
        "train_data"
      ],
      "id": "97ca9c45"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae24c7bb"
      },
      "source": [
        "### Since you have created the \"avg_delay\" column from \"Delay\" and \"clear_date\" column, there is no need of these two columns anymore \n",
        "\n",
        "- You are expected to drop \"Delay\" and \"clear_date\" columns from maindata dataframe "
      ],
      "id": "ae24c7bb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78a61ab9"
      },
      "outputs": [],
      "source": [
        "train_data.drop(['delay', 'clear_date'], axis=1, inplace=True)\n"
      ],
      "id": "78a61ab9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae724bfc"
      },
      "source": [
        "# Splitting of Train and the Test Data"
      ],
      "id": "ae724bfc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb6f0264"
      },
      "source": [
        "### You need to split the \"maindata\" columns into X and y dataframe\n",
        "\n",
        "- Note - y should have the target column i.e. \"avg_delay\" and the other column should be in X\n",
        "\n",
        "- X is going to hold the source fields and y will be going to hold the target fields"
      ],
      "id": "cb6f0264"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75ab29ab"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.iloc[:,:-1].copy()\n"
      ],
      "id": "75ab29ab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6412c62b"
      },
      "outputs": [],
      "source": [
        "Y_train = train_data['avg_delay']\n"
      ],
      "id": "6412c62b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c2942bf"
      },
      "source": [
        "#### You are expected to split both the dataframes into train and test format in 60:40 ratio \n",
        "\n",
        "- Note - The expected output should be in \"X_train\", \"X_loc_test\", \"y_train\", \"y_loc_test\" format "
      ],
      "id": "1c2942bf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d92160a5"
      },
      "outputs": [],
      "source": [
        "x_train, x_loc_test, y_train, y_loc_test = train_test_split(X_train,Y_train,test_size=0.4 )"
      ],
      "id": "d92160a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4OME62pDufR"
      },
      "source": [
        "### Please check for the number of rows and columns of all the new dataframes (all 4)"
      ],
      "id": "p4OME62pDufR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48328d0a"
      },
      "outputs": [],
      "source": [
        "print(\" x training set\", x_train.shape)\n",
        "print(\" y training set\", y_train.shape)\n",
        "print(\" x testing set\", x_loc_test.shape)\n",
        "print(\" y testing set\", y_loc_test.shape)"
      ],
      "id": "48328d0a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a68ed71"
      },
      "source": [
        "### Now you are expected to split the \"X_loc_test\" and \"y_loc_test\" dataset into \"Test\" and \"Validation\" (as the names given below) dataframe with 50:50 format \n",
        "\n",
        "- Note - The expected output should be in \"X_val\", \"X_test\", \"y_val\", \"y_test\" format"
      ],
      "id": "4a68ed71"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b56c62f2"
      },
      "outputs": [],
      "source": [
        "x_val, x_test, y_val, y_test = train_test_split(x_loc_test,y_loc_test,test_size=0.5 )"
      ],
      "id": "b56c62f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJTSAskvERH1"
      },
      "source": [
        "### Please check for the number of rows and columns of all the 4 dataframes "
      ],
      "id": "bJTSAskvERH1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "845d7564"
      },
      "outputs": [],
      "source": [
        "print(\" x validation set\", x_val.shape)\n",
        "print(\" y validation set\", y_val.shape)\n",
        "print(\" x test set\", x_test.shape)\n",
        "print(\" y test set\", y_test.shape)"
      ],
      "id": "845d7564"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "110fa872"
      },
      "source": [
        "# Exploratory Data Analysis (EDA) "
      ],
      "id": "110fa872"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffc8fe0f"
      },
      "source": [
        "### Distribution Plot of the target variable (use the dataframe which contains the target field)\n",
        "\n",
        "- Note - You are expected to make a distribution plot for the target variable "
      ],
      "id": "ffc8fe0f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ba2bf8ed"
      },
      "outputs": [],
      "source": [
        "sns.distplot(train_data.avg_delay)\n"
      ],
      "id": "ba2bf8ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0e323a3"
      },
      "source": [
        "### You are expected to group the X_train dataset on 'name_customer' column with 'doc_id' in the x_train set\n",
        "\n",
        "### Need to store the outcome into a new dataframe \n",
        "\n",
        "- Note code given for groupby statement- X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()"
      ],
      "id": "d0e323a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7acf0ee"
      },
      "outputs": [],
      "source": [
        "nc =X_train.groupby(by=['name_customer'], as_index=False)['doc_id'].count()\n"
      ],
      "id": "f7acf0ee"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA43bFffFt6i"
      },
      "source": [
        "### You can make another distribution plot of the \"doc_id\" column from x_train"
      ],
      "id": "cA43bFffFt6i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9576bf33"
      },
      "outputs": [],
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.distplot(X_train['doc_id'], color='blue')"
      ],
      "id": "9576bf33"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fba2c44f"
      },
      "source": [
        "#### Create a Distribution plot only for business_year and a seperate distribution plot of \"business_year\" column along with the doc_id\" column\n"
      ],
      "id": "fba2c44f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fecec77"
      },
      "outputs": [],
      "source": [
        "sns.distplot(X_train.buisness_year)"
      ],
      "id": "4fecec77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr1jGhfOKjnw"
      },
      "outputs": [],
      "source": [
        "plt.bar(train_data['buisness_year'],train_data['doc_id'])"
      ],
      "id": "qr1jGhfOKjnw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "968fbcc9"
      },
      "source": [
        "# Feature Engineering "
      ],
      "id": "968fbcc9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbh6CyGqH3XE"
      },
      "source": [
        "### Display and describe the X_train dataframe "
      ],
      "id": "jbh6CyGqH3XE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6bcf307"
      },
      "outputs": [],
      "source": [
        "X_train"
      ],
      "id": "e6bcf307"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ccc819"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ],
      "id": "08ccc819"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abd7ac8b"
      },
      "source": [
        "#### The \"business_code\" column inside X_train, is a categorical column, so you need to perform Labelencoder on that particular column\n",
        "\n",
        "- Note - call the Label Encoder from sklearn library and use the fit() function on \"business_code\" column\n",
        "- Note - Please fill in the blanks (two) to complete this code"
      ],
      "id": "abd7ac8b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c223545"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "business_coder = LabelEncoder()\n",
        "business_coder.fit(X_train['business_code'])"
      ],
      "id": "7c223545"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86f7d9c"
      },
      "source": [
        "#### You are expected to store the value into a new column i.e. \"business_code_enc\"\n",
        "\n",
        "- Note - For Training set you are expected to use fit_trainsform()\n",
        "- Note - For Test set you are expected to use the trainsform()\n",
        "- Note - For Validation set you are expected to use the trainsform()\n",
        "\n",
        "\n",
        "- Partial code is provided, please fill in the blanks "
      ],
      "id": "f86f7d9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4269c307"
      },
      "outputs": [],
      "source": [
        "X_train['business_code_enc'] = business_coder.fit_transform(X_train['business_code'])"
      ],
      "id": "4269c307"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70a53712"
      },
      "outputs": [],
      "source": [
        "x_val['business_code_enc'] = business_coder.transform(x_val['business_code'])\n",
        "x_test['business_code_enc'] = business_coder.transform(x_test['business_code'])"
      ],
      "id": "70a53712"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdNYxTkqNfmz"
      },
      "source": [
        "### Display \"business_code\" and \"business_code_enc\" together from X_train dataframe "
      ],
      "id": "gdNYxTkqNfmz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1196a002"
      },
      "outputs": [],
      "source": [
        "X_train.loc[:,[\"business_code\",\"business_code_enc\"]]"
      ],
      "id": "1196a002"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11477224"
      },
      "source": [
        "#### Create a function called \"custom\" for dropping the columns 'business_code' from train, test and validation dataframe\n",
        "\n",
        "- Note - Fill in the blank to complete the code"
      ],
      "id": "11477224"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1052868a"
      },
      "outputs": [],
      "source": [
        "def custom(col ,traindf = X_train,valdf = x_val,testdf = x_test):\n",
        "    traindf.drop(col, axis =1,inplace=True)\n",
        "    valdf.drop(col,axis=1 , inplace=True)\n",
        "    testdf.drop(col,axis=1 , inplace=True)\n",
        "\n",
        "    return traindf,valdf ,testdf"
      ],
      "id": "1052868a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI--ZuMbNLne"
      },
      "source": [
        "### Call the function by passing the column name which needed to be dropped from train, test and validation dataframes. Return updated dataframes to be stored in X_train ,X_val, X_test  \n",
        "\n",
        "- Note = Fill in the blank to complete the code "
      ],
      "id": "rI--ZuMbNLne"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a0f955c"
      },
      "outputs": [],
      "source": [
        "X_train , x_val , x_test = custom([\"business_code\"])\n"
      ],
      "id": "1a0f955c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28b5b27e"
      },
      "source": [
        "### Manually replacing str values with numbers, Here we are trying manually replace the customer numbers with some specific values like, 'CCCA' as 1, 'CCU' as 2 and so on. Also we are converting the datatype \"cust_number\" field to int type.\n",
        "\n",
        "- We are doing it for all the three dataframes as shown below. This is fully completed code. No need to modify anything here \n",
        "\n"
      ],
      "id": "28b5b27e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85dd129e"
      },
      "outputs": [],
      "source": [
        "X_train['cust_number'] = X_train['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
        "x_test['cust_number'] = x_test['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n",
        "x_val['cust_number'] = x_val['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)\n"
      ],
      "id": "85dd129e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8vA-zmdPnJ8"
      },
      "source": [
        "#### It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]. Unknown will be added in fit and transform will take care of new item. It gives unknown class id.\n",
        "\n",
        "#### This will fit the encoder for all the unique values and introduce unknown value\n",
        "\n",
        "- Note - Keep this code as it is, we will be using this later on.  "
      ],
      "id": "U8vA-zmdPnJ8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "151f48ba"
      },
      "outputs": [],
      "source": [
        "#For encoding unseen labels\n",
        "class EncoderExt(object):\n",
        "    def __init__(self):\n",
        "        self.label_encoder = LabelEncoder()\n",
        "    def fit(self, data_list):\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "        return self\n",
        "    def transform(self, data_list):\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "id": "151f48ba"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "254c64e6"
      },
      "source": [
        "### Use the user define Label Encoder function called \"EncoderExt\" for the \"name_customer\" column\n",
        "\n",
        "- Note - Keep the code as it is, no need to change"
      ],
      "id": "254c64e6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62b17eff"
      },
      "outputs": [],
      "source": [
        "label_encoder = EncoderExt()\n",
        "label_encoder.fit(X_train['name_customer'])\n",
        "X_train['name_customer_enc']=label_encoder.transform(X_train['name_customer'])\n",
        "x_val['name_customer_enc']=label_encoder.transform(x_val['name_customer'])\n",
        "x_test['name_customer_enc']=label_encoder.transform(x_test['name_customer'])"
      ],
      "id": "62b17eff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK7LMoy2QZhy"
      },
      "source": [
        "### As we have created the a new column \"name_customer_enc\", so now drop \"name_customer\" column from all three dataframes\n",
        "\n",
        "- Note - Keep the code as it is, no need to change"
      ],
      "id": "mK7LMoy2QZhy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef85f1c0"
      },
      "outputs": [],
      "source": [
        "X_train ,X_val, X_test = custom(['name_customer'])"
      ],
      "id": "ef85f1c0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aa09d22"
      },
      "source": [
        "### Using Label Encoder for the \"cust_payment_terms\" column\n",
        "\n",
        "- Note - Keep the code as it is, no need to change"
      ],
      "id": "3aa09d22"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f9ab642"
      },
      "outputs": [],
      "source": [
        "label_encoder1 = EncoderExt()\n",
        "label_encoder1.fit(X_train['cust_payment_terms'])\n",
        "X_train['cust_payment_terms_enc']=label_encoder1.transform(X_train['cust_payment_terms'])\n",
        "X_val['cust_payment_terms_enc']=label_encoder1.transform(X_val['cust_payment_terms'])\n",
        "X_test['cust_payment_terms_enc']=label_encoder1.transform(X_test['cust_payment_terms'])"
      ],
      "id": "6f9ab642"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55f9a7c2"
      },
      "outputs": [],
      "source": [
        "X_train ,X_val, X_test = custom(['cust_payment_terms'])"
      ],
      "id": "55f9a7c2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0788f42b"
      },
      "source": [
        "## Check the datatype of all the columns of Train, Test and Validation dataframes realted to X\n",
        "\n",
        "- Note - You are expected yo use dtype"
      ],
      "id": "0788f42b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc79a316"
      },
      "outputs": [],
      "source": [
        "X_train.dtypes"
      ],
      "id": "bc79a316"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b33242d8"
      },
      "outputs": [],
      "source": [
        "x_test.dtypes"
      ],
      "id": "b33242d8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bd4da71"
      },
      "outputs": [],
      "source": [
        "x_val.dtypes"
      ],
      "id": "6bd4da71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVfvuPiWPeMB"
      },
      "source": [
        "### From the above output you can notice their are multiple date columns with datetime format\n",
        "\n",
        "### In order to pass it into our model, we need to convert it into float format"
      ],
      "id": "LVfvuPiWPeMB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d344db9"
      },
      "source": [
        "### You need to extract day, month and year from the \"posting_date\" column \n",
        "\n",
        "1.   Extract days from \"posting_date\" column and store it into a new column \"day_of_postingdate\" for train, test and validation dataset \n",
        "2.   Extract months from \"posting_date\" column and store it into a new column \"month_of_postingdate\" for train, test and validation dataset\n",
        "3.   Extract year from \"posting_date\" column and store it into a new column \"year_of_postingdate\" for train, test and validation dataset \n",
        "\n",
        "\n",
        "\n",
        "- Note - You are supposed yo use \n",
        "\n",
        "*   dt.day\n",
        "*   dt.month\n",
        "*   dt.year\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "9d344db9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6e3cdfd6"
      },
      "outputs": [],
      "source": [
        "X_train['day_of_postingdate'] = X_train['posting_date'].dt.day\n",
        "X_train['month_of_postingdate'] = X_train['posting_date'].dt.month\n",
        "X_train['year_of_postingdate'] = X_train['posting_date'].dt.year\n",
        "\n",
        "x_val['day_of_postingdate'] = x_val['posting_date'].dt.day\n",
        "x_val['month_of_postingdate'] = x_val['posting_date'].dt.month\n",
        "x_val['year_of_postingdate'] = x_val['posting_date'].dt.year\n",
        "\n",
        "\n",
        "x_test['day_of_postingdate'] = x_test['posting_date'].dt.day\n",
        "x_test['month_of_postingdate'] = x_test['posting_date'].dt.month\n",
        "x_test['year_of_postingdate'] = x_test['posting_date'].dt.year\n",
        "\n"
      ],
      "id": "6e3cdfd6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyI-F853Rxa7"
      },
      "source": [
        "### pass the \"posting_date\" column into the Custom function for train, test and validation dataset"
      ],
      "id": "GyI-F853Rxa7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQHtQkrnRx_V"
      },
      "outputs": [],
      "source": [
        "X_train ,X_val, X_test = custom(['posting_date'])"
      ],
      "id": "FQHtQkrnRx_V"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMnCaEcKReSw"
      },
      "source": [
        "### You need to extract day, month and year from the \"baseline_create_date\" column \n",
        "\n",
        "1.   Extract days from \"baseline_create_date\" column and store it into a new column \"day_of_createdate\" for train, test and validation dataset \n",
        "2.   Extract months from \"baseline_create_date\" column and store it into a new column \"month_of_createdate\" for train, test and validation dataset\n",
        "3.   Extract year from \"baseline_create_date\" column and store it into a new column \"year_of_createdate\" for train, test and validation dataset \n",
        "\n",
        "\n",
        "\n",
        "- Note - You are supposed yo use \n",
        "\n",
        "*   dt.day\n",
        "*   dt.month\n",
        "*   dt.year\n",
        "\n",
        "\n",
        "- Note - Do as it is been shown in the previous two code boxes"
      ],
      "id": "GMnCaEcKReSw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee4d83d0"
      },
      "source": [
        "### Extracting Day, Month, Year for 'baseline_create_date' column"
      ],
      "id": "ee4d83d0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32b240e1"
      },
      "outputs": [],
      "source": [
        "X_train['day_of_baseline'] = X_train['baseline_create_date'].dt.day\n",
        "X_train['month_of_baseline'] = X_train['baseline_create_date'].dt.month\n",
        "X_train['year_of_baseline'] = X_train['baseline_create_date'].dt.year\n",
        "\n",
        "x_val['day_of_baseline'] = x_val['baseline_create_date'].dt.day\n",
        "x_val['month_of_baseline'] = x_val['baseline_create_date'].dt.month\n",
        "x_val['year_of_baseline'] = x_val['baseline_create_date'].dt.year\n",
        "\n",
        "\n",
        "x_test['day_of_baseline'] = x_test['baseline_create_date'].dt.day\n",
        "x_test['month_of_baseline'] = x_test['baseline_create_date'].dt.month\n",
        "x_test['year_of_baseline'] = x_test['baseline_create_date'].dt.year"
      ],
      "id": "32b240e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFgwkS5rSDDs"
      },
      "source": [
        "### pass the \"baseline_create_date\" column into the Custom function for train, test and validation dataset"
      ],
      "id": "cFgwkS5rSDDs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGYa2BEQSDg3"
      },
      "outputs": [],
      "source": [
        "X_train ,X_val, X_test = custom(['baseline_create_date'])"
      ],
      "id": "RGYa2BEQSDg3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77c7a0df"
      },
      "source": [
        "### You need to extract day, month and year from the \"due_in_date\" column \n",
        "\n",
        "1.   Extract days from \"due_in_date\" column and store it into a new column \"day_of_due\" for train, test and validation dataset \n",
        "2.   Extract months from \"due_in_date\" column and store it into a new column \"month_of_due\" for train, test and validation dataset\n",
        "3.   Extract year from \"due_in_date\" column and store it into a new column \"year_of_due\" for train, test and validation dataset \n",
        "\n",
        "\n",
        "\n",
        "- Note - You are supposed yo use \n",
        "\n",
        "*   dt.day\n",
        "*   dt.month\n",
        "*   dt.year\n",
        "\n",
        "- Note - Do as it is been shown in the previous code"
      ],
      "id": "77c7a0df"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c745547"
      },
      "outputs": [],
      "source": [
        "X_train['day_of_due'] = X_train['due_in_date'].dt.day\n",
        "X_train['month_of_due'] = X_train['due_in_date'].dt.month\n",
        "X_train['year_of_due'] = X_train['due_in_date'].dt.year\n",
        "\n",
        "x_val['day_of_due'] = x_val['due_in_date'].dt.day\n",
        "x_val['month_of_due'] = x_val['due_in_date'].dt.month\n",
        "x_val['year_of_due'] = x_val['due_in_date'].dt.year\n",
        "\n",
        "\n",
        "x_test['day_of_due'] = x_test['due_in_date'].dt.day\n",
        "x_test['month_of_due'] = x_test['due_in_date'].dt.month\n",
        "x_test['year_of_due'] = x_test['due_in_date'].dt.year"
      ],
      "id": "5c745547"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYLLzulGSvRd"
      },
      "source": [
        "pass the \"due_in_date\" column into the Custom function for train, test and validation dataset"
      ],
      "id": "FYLLzulGSvRd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-s6QuY9Svrh"
      },
      "outputs": [],
      "source": [
        "X_train ,X_val, X_test = custom(['due_in_date'])"
      ],
      "id": "1-s6QuY9Svrh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ae5d052"
      },
      "source": [
        "### Check for the datatypes for train, test and validation set again\n",
        "\n",
        "- Note - all the data type should be in either int64 or float64 format \n"
      ],
      "id": "1ae5d052"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aee9d828"
      },
      "outputs": [],
      "source": [
        "X_train.dtypes\n"
      ],
      "id": "aee9d828"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMkasjfrfpUD"
      },
      "outputs": [],
      "source": [
        "x_test.dtypes\n"
      ],
      "id": "wMkasjfrfpUD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBeTPRKafqRB"
      },
      "outputs": [],
      "source": [
        "x_val.dtypes"
      ],
      "id": "WBeTPRKafqRB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65810f55"
      },
      "source": [
        "# Feature Selection"
      ],
      "id": "65810f55"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bb1ad9f"
      },
      "source": [
        "### Filter Method\n",
        "\n",
        "- Calling the VarianceThreshold Function \n",
        "- Note - Keep the code as it is, no need to change "
      ],
      "id": "4bb1ad9f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e882509f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "constant_filter = VarianceThreshold(threshold=0)\n",
        "constant_filter.fit(X_train)\n",
        "len(X_train.columns[constant_filter.get_support()])"
      ],
      "id": "e882509f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9531H3jR-W2"
      },
      "source": [
        "- Note - Keep the code as it is, no need to change \n"
      ],
      "id": "V9531H3jR-W2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c77c12e1"
      },
      "outputs": [],
      "source": [
        "constant_columns = [column for column in X_train.columns\n",
        "                    if column not in X_train.columns[constant_filter.get_support()]]\n",
        "print(len(constant_columns))"
      ],
      "id": "c77c12e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d9b8610"
      },
      "source": [
        "- transpose the feature matrice\n",
        "- print the number of duplicated features\n",
        "- select the duplicated features columns names\n",
        "\n",
        "- Note - Keep the code as it is, no need to change \n"
      ],
      "id": "6d9b8610"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fb7db95"
      },
      "outputs": [],
      "source": [
        "x_train_T = X_train.T\n",
        "print(x_train_T.duplicated().sum())\n",
        "duplicated_columns = x_train_T[x_train_T.duplicated()].index.values"
      ],
      "id": "0fb7db95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "510fa831"
      },
      "source": [
        "### Filtering depending upon correlation matrix value\n",
        "- We have created a function called handling correlation which is going to return fields based on the correlation matrix value with a threshold of 0.8\n",
        "\n",
        "- Note - Keep the code as it is, no need to change "
      ],
      "id": "510fa831"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67731abc"
      },
      "outputs": [],
      "source": [
        "def handling_correlation(X_train,threshold=0.8):\n",
        "    corr_features = set()\n",
        "    corr_matrix = X_train.corr()\n",
        "    for i in range(len(corr_matrix .columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) >threshold:\n",
        "                colname = corr_matrix.columns[i]\n",
        "                corr_features.add(colname)\n",
        "    return list(corr_features)"
      ],
      "id": "67731abc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaE_6qVgSXl3"
      },
      "source": [
        "- Note : Here we are trying to find out the relevant fields, from X_train\n",
        "- Please fill in the blanks to call handling_correlation() function with a threshold value of 0.85"
      ],
      "id": "JaE_6qVgSXl3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd91d1a2"
      },
      "outputs": [],
      "source": [
        "train=X_train.copy()\n",
        "handling_correlation(train.copy(),0.85)"
      ],
      "id": "dd91d1a2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "154da511"
      },
      "source": [
        "### Heatmap for X_train\n",
        "\n",
        "- Note - Keep the code as it is, no need to change"
      ],
      "id": "154da511"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e8f2fe4"
      },
      "outputs": [],
      "source": [
        "colormap = plt.cm.RdBu\n",
        "plt.figure(figsize=(18,18))\n",
        "plt.title('Pearson Correlation of Features', y=1.05, size=20)\n",
        "sns.heatmap(x_train.merge(y_train , on = x_train.index ).corr(),linewidths=0.1,vmax=1.0, \n",
        "            square=True, cmap='gist_rainbow_r', linecolor='white', annot=True)"
      ],
      "id": "2e8f2fe4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3b0d745"
      },
      "source": [
        "#### Calling variance threshold for threshold value = 0.8\n",
        "\n",
        "- Note -  Fill in the blanks to call the appropriate method"
      ],
      "id": "e3b0d745"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9b2080f"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import VarianceThreshold\n",
        "sel = VarianceThreshold(0.8)\n",
        "sel.fit(X_train)"
      ],
      "id": "a9b2080f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cb8c3dc"
      },
      "outputs": [],
      "source": [
        "sel.variances_"
      ],
      "id": "6cb8c3dc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62633a84"
      },
      "source": [
        "### Features columns are \n",
        "- 'year_of_createdate' \n",
        "- 'year_of_due'\n",
        "- 'day_of_createdate'\n",
        "- 'year_of_postingdate'\n",
        "- 'month_of_due'\n",
        "- 'month_of_createdate'"
      ],
      "id": "62633a84"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "651f1ad0"
      },
      "source": [
        "# Modelling \n",
        "\n",
        "#### Now you need to compare with different machine learning models, and needs to find out the best predicted model\n",
        "\n",
        "- Linear Regression\n",
        "- Decision Tree Regression\n",
        "- Random Forest Regression\n",
        "- Support Vector Regression\n",
        "- Extreme Gradient Boost Regression "
      ],
      "id": "651f1ad0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PicEhSuUUOkt"
      },
      "source": [
        "### You need to make different blank list for different evaluation matrix \n",
        "\n",
        "- MSE\n",
        "- R2\n",
        "- Algorithm"
      ],
      "id": "PicEhSuUUOkt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "701e12b0"
      },
      "outputs": [],
      "source": [
        "MSE_Score = []\n",
        "R2_Score = []\n",
        "Algorithm = []\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "id": "701e12b0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29310119"
      },
      "source": [
        "### You need to start with the baseline model Linear Regression\n",
        "\n",
        "- Step 1 : Call the Linear Regression from sklearn library\n",
        "- Step 2 : make an object of Linear Regression \n",
        "- Step 3 : fit the X_train and y_train dataframe into the object \n",
        "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
      ],
      "id": "29310119"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bdea395"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "Algorithm.append('LinearRegression')\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, Y_train)\n",
        "predicted= regressor.predict(X_test)"
      ],
      "id": "6bdea395"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G02cpnBhXJ14"
      },
      "source": [
        "### Check for the \n",
        "\n",
        "- Mean Square Error\n",
        "- R Square Error \n",
        "\n",
        "for y_test and predicted dataset and store those data inside respective list for comparison "
      ],
      "id": "G02cpnBhXJ14"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0f69ca19"
      },
      "outputs": [],
      "source": [
        "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
        "R2_Score.append(r2_score(y_test, predicted))\n"
      ],
      "id": "0f69ca19"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsmScbHjYMv1"
      },
      "source": [
        "### Check the same for the Validation set also "
      ],
      "id": "CsmScbHjYMv1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe653295"
      },
      "outputs": [],
      "source": [
        "predict_test= regressor.predict(X_val)\n",
        "mean_squared_error(y_val, predict_test, squared=False)"
      ],
      "id": "fe653295"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LokxV2LGYUVh"
      },
      "source": [
        "### Display The Comparison Lists"
      ],
      "id": "LokxV2LGYUVh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c405bd3"
      },
      "outputs": [],
      "source": [
        "for i in Algorithm, MSE_Score, R2_Score:\n",
        "    print(i,end=',')"
      ],
      "id": "9c405bd3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0e65c86"
      },
      "source": [
        "### You need to start with the baseline model Support Vector Regression\n",
        "\n",
        "- Step 1 : Call the Support Vector Regressor from sklearn library\n",
        "- Step 2 : make an object of SVR\n",
        "- Step 3 : fit the X_train and y_train dataframe into the object \n",
        "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
      ],
      "id": "b0e65c86"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccb5de08"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "Algorithm.append('SVR')\n",
        "regressor = SVR()\n",
        "regressor.fit(X_train, Y_train)\n",
        "predicted= regressor.predict(X_test)"
      ],
      "id": "ccb5de08"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zz9kcrViYt7e"
      },
      "source": [
        "### Check for the \n",
        "\n",
        "- Mean Square Error\n",
        "- R Square Error \n",
        "\n",
        "for \"y_test\" and \"predicted\" dataset and store those data inside respective list for comparison "
      ],
      "id": "zz9kcrViYt7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bb9db76"
      },
      "outputs": [],
      "source": [
        "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
        "R2_Score.append(r2_score(y_test, predicted))\n",
        "\n"
      ],
      "id": "5bb9db76"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YAxd8N9Y0hJ"
      },
      "source": [
        "### Check the same for the Validation set also "
      ],
      "id": "0YAxd8N9Y0hJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6ee71b1"
      },
      "outputs": [],
      "source": [
        "predict_test= regressor.predict(X_val)\n",
        "mean_squared_error(y_val, predict_test, squared=False)"
      ],
      "id": "d6ee71b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGcqS5EcY4BI"
      },
      "source": [
        "### Display The Comparison Lists"
      ],
      "id": "eGcqS5EcY4BI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa72c1ec"
      },
      "outputs": [],
      "source": [
        "for i in Algorithm, MSE_Score, R2_Score:\n",
        "    print(i,end=',')"
      ],
      "id": "aa72c1ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dad18bb3"
      },
      "source": [
        "### Your next model would be Decision Tree Regression\n",
        "\n",
        "- Step 1 : Call the Decision Tree Regressor from sklearn library\n",
        "- Step 2 : make an object of Decision Tree\n",
        "- Step 3 : fit the X_train and y_train dataframe into the object \n",
        "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
      ],
      "id": "dad18bb3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b6a51eb"
      },
      "outputs": [],
      "source": [
        "Algorithm.append('DecisionTreeRegressor')\n",
        "regressor = DecisionTreeRegressor()\n",
        "regressor.fit(X_train, Y_train)\n",
        "predicted= regressor.predict(X_test)"
      ],
      "id": "1b6a51eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOzfgfeOZo3F"
      },
      "source": [
        "### Check for the \n",
        "\n",
        "- Mean Square Error\n",
        "- R Square Error \n",
        "\n",
        "for y_test and predicted dataset and store those data inside respective list for comparison "
      ],
      "id": "AOzfgfeOZo3F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "776e6983"
      },
      "outputs": [],
      "source": [
        "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
        "R2_Score.append(r2_score(y_test, predicted))\n",
        "\n"
      ],
      "id": "776e6983"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI6d49DQZrhW"
      },
      "source": [
        "### Check the same for the Validation set also "
      ],
      "id": "eI6d49DQZrhW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "155fb55c"
      },
      "outputs": [],
      "source": [
        "predict_test= regressor.predict(X_val)\n",
        "mean_squared_error(y_val, predict_test, squared=False)"
      ],
      "id": "155fb55c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbGXvBLQZw5E"
      },
      "source": [
        "### Display The Comparison Lists"
      ],
      "id": "sbGXvBLQZw5E"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d74d515"
      },
      "outputs": [],
      "source": [
        "for i in Algorithm, MSE_Score, R2_Score:\n",
        "    print(i,end=',')"
      ],
      "id": "1d74d515"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ae9979b"
      },
      "source": [
        "### Your next model would be Random Forest Regression\n",
        "\n",
        "- Step 1 : Call the Random Forest Regressor from sklearn library\n",
        "- Step 2 : make an object of Random Forest\n",
        "- Step 3 : fit the X_train and y_train dataframe into the object \n",
        "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Note - Append the Algorithm name into the algorithm list for tracking purpose"
      ],
      "id": "4ae9979b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a69e476a"
      },
      "outputs": [],
      "source": [
        "Algorithm.append('RandomForestRegressor')\n",
        "regressor = RandomForestRegressor()\n",
        "regressor.fit(X_train, Y_train)\n",
        "predicted= regressor.predict(X_test)"
      ],
      "id": "a69e476a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNcEJF-6anof"
      },
      "source": [
        "### Check for the \n",
        "\n",
        "- Mean Square Error\n",
        "- R Square Error \n",
        "\n",
        "for y_test and predicted dataset and store those data inside respective list for comparison "
      ],
      "id": "XNcEJF-6anof"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6Wbkk1JkviT"
      },
      "outputs": [],
      "source": [
        "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
        "R2_Score.append(r2_score(y_test, predicted))\n"
      ],
      "id": "f6Wbkk1JkviT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMbyr9V4ati1"
      },
      "source": [
        "### Check the same for the Validation set also "
      ],
      "id": "yMbyr9V4ati1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55b9fb54"
      },
      "outputs": [],
      "source": [
        "predict_test= regressor.predict(X_val)\n",
        "mean_squared_error(y_val, predict_test, squared=False)"
      ],
      "id": "55b9fb54"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiBawcCsaw_Z"
      },
      "source": [
        "### Display The Comparison Lists\n"
      ],
      "id": "tiBawcCsaw_Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8277c13e"
      },
      "outputs": [],
      "source": [
        "for i in Algorithm, MSE_Score, R2_Score:\n",
        "    print(i,end=',')"
      ],
      "id": "8277c13e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6b21881"
      },
      "source": [
        "### The last but not the least model would be XGBoost or Extreme Gradient Boost Regression\n",
        "\n",
        "- Step 1 : Call the XGBoost Regressor from xgb library\n",
        "- Step 2 : make an object of Xgboost\n",
        "- Step 3 : fit the X_train and y_train dataframe into the object \n",
        "- Step 4 : Predict the output by passing the X_test Dataset into predict function\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Note - Append the Algorithm name into the algorithm list for tracking purpose### Extreme Gradient Boost Regression\n",
        "- Note -  No need to change the code "
      ],
      "id": "e6b21881"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "705a38ec"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "Algorithm.append('XGB Regressor')\n",
        "regressor = xgb.XGBRegressor()\n",
        "regressor.fit(X_train, Y_train)\n",
        "predicted = regressor.predict(X_test)"
      ],
      "id": "705a38ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ierNZkb9bQDD"
      },
      "source": [
        "### Check for the \n",
        "\n",
        "- Mean Square Error\n",
        "- R Square Error \n",
        "\n",
        "for y_test and predicted dataset and store those data inside respective list for comparison "
      ],
      "id": "ierNZkb9bQDD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "507a9d2f"
      },
      "outputs": [],
      "source": [
        "MSE_Score.append(mean_squared_error(y_test, predicted))\n",
        "R2_Score.append(r2_score(y_test, predicted))\n"
      ],
      "id": "507a9d2f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84UZ2ojsbWaH"
      },
      "source": [
        "### Check the same for the Validation set also "
      ],
      "id": "84UZ2ojsbWaH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e78ac250"
      },
      "outputs": [],
      "source": [
        "predict_test= regressor.predict(X_val)\n",
        "mean_squared_error(y_val, predict_test, squared=False)"
      ],
      "id": "e78ac250"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FJFyaVbbbAH"
      },
      "source": [
        "### Display The Comparison Lists\n"
      ],
      "id": "9FJFyaVbbbAH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f765ba35"
      },
      "outputs": [],
      "source": [
        "for i in Algorithm, MSE_Score, R2_Score:\n",
        "    print(i,end=',')"
      ],
      "id": "f765ba35"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a71bc90f"
      },
      "source": [
        "## You need to make the comparison list into a comparison dataframe "
      ],
      "id": "a71bc90f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEXuq5_XC1nZ"
      },
      "outputs": [],
      "source": [
        "df1 = pd.DataFrame (Algorithm, columns = ['Algorithm'])\n",
        "df2 = pd.DataFrame (MSE_Score, columns = ['MSE_Score'])\n",
        "df3= pd.DataFrame (R2_Score, columns = ['R2_Score'])\n",
        "df4 = pd.concat([df1, df2, df3], axis = 0)\n",
        "df4"
      ],
      "id": "FEXuq5_XC1nZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62e61c60"
      },
      "source": [
        "## Now from the Comparison table, you need to choose the best fit model\n",
        "\n",
        "- Step 1 - Fit X_train and y_train inside the model \n",
        "- Step 2 - Predict the X_test dataset\n",
        "- Step 3 - Predict the X_val dataset\n",
        "\n",
        "\n",
        "- Note - No need to change the code"
      ],
      "id": "62e61c60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3e07c258"
      },
      "outputs": [],
      "source": [
        "regressorfinal = xgb.XGBRegressor()\n",
        "regressorfinal.fit(X_train, Y_train)\n",
        "predictedfinal = regressorfinal.predict(X_test)\n",
        "predict_testfinal = regressorfinal.predict(X_val)"
      ],
      "id": "3e07c258"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e4df6c4"
      },
      "source": [
        "### Calculate the Mean Square Error for test dataset\n",
        "\n",
        "- Note - No need to change the code"
      ],
      "id": "8e4df6c4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fb466d0"
      },
      "outputs": [],
      "source": [
        "mean_squared_error(y_test,predictedfinal,squared=False)"
      ],
      "id": "5fb466d0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce27f87f"
      },
      "source": [
        "### Calculate the mean Square Error for validation dataset"
      ],
      "id": "ce27f87f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b47978ea"
      },
      "outputs": [],
      "source": [
        "mean_squared_error(y_val,predictedfinal,squared=False)"
      ],
      "id": "b47978ea"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30014dbd"
      },
      "source": [
        "### Calculate the R2 score for test"
      ],
      "id": "30014dbd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a162737"
      },
      "outputs": [],
      "source": [
        "r2_score(y_test, predictedfinal)\n"
      ],
      "id": "8a162737"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c9853b0"
      },
      "source": [
        "### Calculate the R2 score for Validation"
      ],
      "id": "1c9853b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a6dc77c"
      },
      "outputs": [],
      "source": [
        "r2_score(y_val, predictedfinal)"
      ],
      "id": "1a6dc77c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "499522d9"
      },
      "source": [
        "### Calculate the Accuracy for train Dataset "
      ],
      "id": "499522d9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a4f1ce8"
      },
      "outputs": [],
      "source": [
        "regressorfinal.score(X_train,Y_train)"
      ],
      "id": "7a4f1ce8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12a1c921"
      },
      "source": [
        "### Calculate the accuracy for validation"
      ],
      "id": "12a1c921"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2579b4f"
      },
      "outputs": [],
      "source": [
        "regressorfinal.score(x_val,y_val)"
      ],
      "id": "d2579b4f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79b82e84"
      },
      "source": [
        "### Calculate the accuracy for test"
      ],
      "id": "79b82e84"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f09e6431"
      },
      "outputs": [],
      "source": [
        "regressorfinal.score(x_test,y_test)"
      ],
      "id": "f09e6431"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9488a5d9"
      },
      "source": [
        "## Specify the reason behind choosing your machine learning model \n",
        "\n",
        "- Note : Provide your answer as a text here"
      ],
      "id": "9488a5d9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "387a6519"
      },
      "source": [
        "## Now you need to pass the Nulldata dataframe into this machine learning model\n",
        "\n",
        "#### In order to pass this Nulldata dataframe into the ML model, we need to perform the following\n",
        "\n",
        "- Step 1 : Label Encoding \n",
        "- Step 2 : Day, Month and Year extraction \n",
        "- Step 3 : Change all the column data type into int64 or float64\n",
        "- Step 4 : Need to drop the useless columns "
      ],
      "id": "387a6519"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7JuxAkdiAdI"
      },
      "source": [
        "### Display the Nulldata "
      ],
      "id": "I7JuxAkdiAdI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6d6a51d2"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ],
      "id": "6d6a51d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vamx5xqtiHCH"
      },
      "source": [
        "### Check for the number of rows and columns in the nulldata"
      ],
      "id": "Vamx5xqtiHCH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59de1092"
      },
      "outputs": [],
      "source": [
        "sum([True for idx,row in df.iterrows() if any(row.isnull())])\n"
      ],
      "id": "59de1092"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxzHNbBjpqXL"
      },
      "source": [
        "### Check the Description and Information of the nulldata "
      ],
      "id": "BxzHNbBjpqXL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6294d29"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ],
      "id": "a6294d29"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe860d94"
      },
      "source": [
        "### Storing the Nulldata into a different dataset \n",
        "# for BACKUP"
      ],
      "id": "fe860d94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16352034"
      },
      "outputs": [],
      "source": [
        "nulldata = df[df.clear_date.isnull()].reset_index()\n",
        "nulldata.drop(columns=['index'],inplace=True)"
      ],
      "id": "16352034"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00f35b8c"
      },
      "source": [
        "### Call the Label Encoder for Nulldata\n",
        "\n",
        "- Note - you are expected to fit \"business_code\" as it is a categorical variable\n",
        "- Note - No need to change the code"
      ],
      "id": "00f35b8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baf04b17"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "business_codern = LabelEncoder()\n",
        "business_codern.fit(nulldata['business_code'])\n",
        "nulldata['business_code_enc'] = business_codern.transform(nulldata['business_code'])"
      ],
      "id": "baf04b17"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLFsWmYYKi_S"
      },
      "outputs": [],
      "source": [
        "nulldata.head(50)"
      ],
      "id": "qLFsWmYYKi_S"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCPBK9karIR-"
      },
      "source": [
        "### Now you need to manually replacing str values with numbers\n",
        "- Note - No need to change the code"
      ],
      "id": "ZCPBK9karIR-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c64924be"
      },
      "outputs": [],
      "source": [
        "nulldata['cust_number'] = nulldata['cust_number'].str.replace('CCCA',\"1\").str.replace('CCU',\"2\").str.replace('CC',\"3\").astype(int)"
      ],
      "id": "c64924be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a55f5f6"
      },
      "source": [
        "## You need to extract day, month and year from the \"clear_date\", \"posting_date\", \"due_in_date\", \"baseline_create_date\" columns\n",
        "\n",
        "\n",
        "##### 1.   Extract day from \"clear_date\" column and store it into 'day_of_cleardate'\n",
        "##### 2.   Extract month from \"clear_date\" column and store it into 'month_of_cleardate'\n",
        "##### 3.   Extract year from \"clear_date\" column and store it into 'year_of_cleardate'\n",
        "\n",
        "\n",
        "\n",
        "##### 4.   Extract day from \"posting_date\" column and store it into 'day_of_postingdate'\n",
        "##### 5.   Extract month from \"posting_date\" column and store it into 'month_of_postingdate'\n",
        "##### 6.   Extract year from \"posting_date\" column and store it into 'year_of_postingdate'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### 7.   Extract day from \"due_in_date\" column and store it into 'day_of_due'\n",
        "##### 8.   Extract month from \"due_in_date\" column and store it into 'month_of_due'\n",
        "##### 9.   Extract year from \"due_in_date\" column and store it into 'year_of_due'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### 10.   Extract day from \"baseline_create_date\" column and store it into 'day_of_createdate'\n",
        "##### 11.   Extract month from \"baseline_create_date\" column and store it into 'month_of_createdate'\n",
        "##### 12.   Extract year from \"baseline_create_date\" column and store it into 'year_of_createdate'\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "- Note - You are supposed To use - \n",
        "\n",
        "*   dt.day\n",
        "*   dt.month\n",
        "*   dt.year"
      ],
      "id": "9a55f5f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdE4g_BXNPdF"
      },
      "outputs": [],
      "source": [
        "nulldata['clear_date']=pd.to_datetime(nulldata['clear_date'],format='%d-%m-%y %H:%M')\n",
        "nulldata['posting_date']=pd.to_datetime(nulldata['posting_date'],format='%d-%m-%y')\n",
        "nulldata['due_in_date']=pd.to_datetime(nulldata['due_in_date'],format='%Y%m%d')\n",
        "nulldata['baseline_create_date']=pd.to_datetime(nulldata['baseline_create_date'],format='%Y%m%d')"
      ],
      "id": "YdE4g_BXNPdF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G5DTMD6MLTRp"
      },
      "outputs": [],
      "source": [
        "nulldata['day_of_cleardate'] = nulldata['clear_date'].dt.day\n",
        "nulldata['month_of_cleardate'] = nulldata['clear_date'].dt.month\n",
        "nulldata['year_of_cleardate'] = nulldata['clear_date'].dt.year"
      ],
      "id": "G5DTMD6MLTRp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-mEe1NmL9JK"
      },
      "outputs": [],
      "source": [
        "nulldata['day_of_postingdate'] = nulldata['posting_date'].dt.day\n",
        "nulldata['month_of_postingdate'] = nulldata['posting_date'].dt.month\n",
        "nulldata['year_of_postingdate'] = nulldata['posting_date'].dt.year"
      ],
      "id": "k-mEe1NmL9JK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4166fbe4"
      },
      "outputs": [],
      "source": [
        "nulldata['day_of_due'] = nulldata['due_in_date'].dt.day\n",
        "nulldata['month_of_due'] = nulldata['due_in_date'].dt.month\n",
        "nulldata['year_of_due'] = nulldata['due_in_date'].dt.year"
      ],
      "id": "4166fbe4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydoDh7brL9JL"
      },
      "outputs": [],
      "source": [
        "nulldata['day_of_baseline'] = nulldata['baseline_create_date'].dt.day\n",
        "nulldata['month_of_baseline'] = nulldata['baseline_create_date'].dt.month\n",
        "nulldata['year_of_baseline'] = nulldata['baseline_create_date'].dt.year"
      ],
      "id": "ydoDh7brL9JL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeHWJYrAvOC6"
      },
      "source": [
        "### Use Label Encoder1 of all the following columns - \n",
        "- 'cust_payment_terms' and store into 'cust_payment_terms_enc'\n",
        "- 'business_code' and store into 'business_code_enc'\n",
        "- 'name_customer' and store into 'name_customer_enc'\n",
        "\n",
        "Note - No need to change the code"
      ],
      "id": "QeHWJYrAvOC6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bac330e2"
      },
      "outputs": [],
      "source": [
        "nulldata['cust_payment_terms_enc']=label_encoder1.transform(nulldata['cust_payment_terms'])\n",
        "nulldata['business_code_enc']=label_encoder1.transform(nulldata['business_code'])\n",
        "nulldata['name_customer_enc']=label_encoder.transform(nulldata['name_customer'])\n"
      ],
      "id": "bac330e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD9I-XqQwC28"
      },
      "source": [
        "### Check for the datatypes of all the columns of Nulldata"
      ],
      "id": "zD9I-XqQwC28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4f72517"
      },
      "outputs": [],
      "source": [
        "nulldata.dtypes"
      ],
      "id": "d4f72517"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17cd5452"
      },
      "source": [
        "### Now you need to drop all the unnecessary columns - \n",
        "\n",
        "- 'business_code'\n",
        "- \"baseline_create_date\"\n",
        "- \"due_in_date\"\n",
        "- \"posting_date\"\n",
        "- \"name_customer\"\n",
        "- \"clear_date\"\n",
        "- \"cust_payment_terms\"\n",
        "- 'day_of_cleardate'\n",
        "- \"month_of_cleardate\"\n",
        "- \"year_of_cleardate\""
      ],
      "id": "17cd5452"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7c82076"
      },
      "outputs": [],
      "source": [
        "nulldata.drop(['business_code', 'baseline_create_date', 'due_in_date', 'posting_date', 'name_customer', 'clear_date', 'cust_payment_terms', 'day_of_cleardate', 'month_of_cleardate','year_of_cleardate'], axis=1, inplace=True)\n"
      ],
      "id": "d7c82076"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_NCr9IPweVq"
      },
      "source": [
        "### Check the information of the \"nulldata\" dataframe"
      ],
      "id": "Q_NCr9IPweVq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e7ffee0"
      },
      "outputs": [],
      "source": [
        "nulldata.info()"
      ],
      "id": "4e7ffee0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XvjhWqmwi-C"
      },
      "source": [
        "### Compare \"nulldata\" with the \"X_test\" dataframe \n",
        "\n",
        "- use info() method"
      ],
      "id": "-XvjhWqmwi-C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02f4b62d"
      },
      "outputs": [],
      "source": [
        "comp = nulldata.info()!= x_test.info()"
      ],
      "id": "02f4b62d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us3ey-9zwqjq"
      },
      "source": [
        "### You must have noticed that there is a mismatch in the column sequence while compairing the dataframes\n",
        "\n",
        "- Note - In order to fed into the machine learning model, you need to edit the sequence of \"nulldata\", similar to the \"X_test\" dataframe"
      ],
      "id": "Us3ey-9zwqjq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vduVNt1kxPW-"
      },
      "source": [
        "- Display all the columns of the X_test dataframe \n",
        "- Display all the columns of the Nulldata dataframe \n",
        "- Store the Nulldata with new sequence into a new dataframe \n",
        "\n",
        "\n",
        "- Note - The code is given below, no need to change "
      ],
      "id": "vduVNt1kxPW-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6729353e"
      },
      "outputs": [],
      "source": [
        "X_test.columns"
      ],
      "id": "6729353e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "47bd9c5e"
      },
      "outputs": [],
      "source": [
        "nulldata.columns"
      ],
      "id": "47bd9c5e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa5a2103"
      },
      "outputs": [],
      "source": [
        "nulldata2=nulldata[['cust_number', 'buisness_year', 'doc_id', 'converted_usd',\n",
        "       'business_code_enc', 'name_customer_enc', 'cust_payment_terms_enc',\n",
        "       'day_of_postingdate', 'month_of_postingdate', 'year_of_postingdate',\n",
        "       'day_of_baseline', 'month_of_baseline', 'year_of_baseline',\n",
        "       'day_of_due', 'month_of_due', 'year_of_due']]"
      ],
      "id": "aa5a2103"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dc8b021"
      },
      "source": [
        "### Display the Final Dataset"
      ],
      "id": "1dc8b021"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f39785a"
      },
      "outputs": [],
      "source": [
        "test_data"
      ],
      "id": "2f39785a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27b88c5a"
      },
      "source": [
        "### Now you can pass this dataset into you final model and store it into \"final_result\""
      ],
      "id": "27b88c5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9YCLAxIadsxJ"
      },
      "outputs": [],
      "source": [
        "params={\n",
        " \"learning_rate\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
        " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
        "    \n",
        "}"
      ],
      "id": "9YCLAxIadsxJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8Nqi-Lcd0kp"
      },
      "outputs": [],
      "source": [
        "reg=xgb.XGBRegressor()\n",
        "random_search=RandomizedSearchCV(reg,param_distributions=params,n_iter=5,n_jobs=-1,cv=5,verbose=3)"
      ],
      "id": "b8Nqi-Lcd0kp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LkByK0n1d2sn"
      },
      "outputs": [],
      "source": [
        "random_search.fit(X_train, Y_train)\n"
      ],
      "id": "LkByK0n1d2sn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEMYb0_oehb4"
      },
      "outputs": [],
      "source": [
        "random_search.best_estimator_\n"
      ],
      "id": "vEMYb0_oehb4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2YGI2Qce2Wv"
      },
      "outputs": [],
      "source": [
        "cl = xgb.XGBRegressor(colsample_bytree=0.3, gamma=0.0, learning_rate=0.2, max_depth=15,\n",
        "             min_child_weight=5)\n",
        "cl.fit(X_train, Y_train)\n",
        "predicted = cl.predict(x_test)"
      ],
      "id": "u2YGI2Qce2Wv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9ECw_fkf4MB"
      },
      "outputs": [],
      "source": [
        "predicted=np.around(predicted)\n",
        "predicted.astype(int)"
      ],
      "id": "Y9ECw_fkf4MB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weEnjH9egZky"
      },
      "outputs": [],
      "source": [
        "Col=pd.DataFrame()\n"
      ],
      "id": "weEnjH9egZky"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YbtYxq_gdPy"
      },
      "outputs": [],
      "source": [
        "avg_Delay=[]\n",
        "for x in predicted:\n",
        "    avg_Delay.append(pd.Timedelta(days=x))\n",
        "Col['avg_delay'] = avg_Delay\n",
        "Col"
      ],
      "id": "-YbtYxq_gdPy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JlGXizLmolKp"
      },
      "outputs": [],
      "source": [
        "final_result = pd.DataFrame(x_test.copy())"
      ],
      "id": "JlGXizLmolKp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MtqUBOsEpD96"
      },
      "outputs": [],
      "source": [
        "final_result"
      ],
      "id": "MtqUBOsEpD96"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9653d3c6"
      },
      "source": [
        "### you need to make the final_result as dataframe, with a column name \"avg_delay\"\n",
        "\n",
        "- Note - No need to change the code"
      ],
      "id": "9653d3c6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25ef814d"
      },
      "outputs": [],
      "source": [
        "final_result['Avg_Delay'] = avg_Delay\n",
        "final_result.head(10)"
      ],
      "id": "25ef814d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C86staIhyf2C"
      },
      "source": [
        "### Display the \"avg_delay\" column"
      ],
      "id": "C86staIhyf2C"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fd46406"
      },
      "outputs": [],
      "source": [
        "final_result['Avg_Delay']"
      ],
      "id": "4fd46406"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44f71a7e"
      },
      "source": [
        "### Now you need to merge this final_result dataframe with the BACKUP of \"nulldata\" Dataframe which we have created in earlier steps"
      ],
      "id": "44f71a7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxJQIDUw1hLL"
      },
      "outputs": [],
      "source": [
        "final = pd.DataFrame(pd.concat([nulldata2, final_result], axis=0))\n"
      ],
      "id": "KxJQIDUw1hLL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-hLtxXgy4GZ"
      },
      "source": [
        "### Display the \"Final\" dataframe "
      ],
      "id": "G-hLtxXgy4GZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "71fb4dc0"
      },
      "outputs": [],
      "source": [
        "final"
      ],
      "id": "71fb4dc0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sc27Uz-y-0O"
      },
      "source": [
        "### Check for the Number of Rows and Columns in your \"Final\" dataframe "
      ],
      "id": "4sc27Uz-y-0O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bst1OhuiA8Ye"
      },
      "outputs": [],
      "source": [
        "final.dtypes"
      ],
      "id": "Bst1OhuiA8Ye"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iUXOIhzy_HR"
      },
      "outputs": [],
      "source": [
        "final.shape"
      ],
      "id": "5iUXOIhzy_HR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48886d2c"
      },
      "source": [
        "### Now, you need to do convert the below fields back into date and time format \n",
        "\n",
        "- Convert \"due_in_date\" into datetime format\n",
        "- Convert \"avg_delay\" into datetime format\n",
        "- Create a new column \"clear_date\" and store the sum of \"due_in_date\" and \"avg_delay\"\n",
        "- display the new \"clear_date\" column\n",
        "- Note - Code is given below, no need to change "
      ],
      "id": "48886d2c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hy80t6e1DN2q"
      },
      "outputs": [],
      "source": [
        "final_result['due_in_date'] = final_result['year_of_due'].map(str)  + final_result['month_of_due'].map(str)  + final_result['day_of_due'].map(str)\n"
      ],
      "id": "hy80t6e1DN2q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JX7jK4_3LP08"
      },
      "outputs": [],
      "source": [
        "final_result['due_in_date']=pd.to_datetime(final_result['due_in_date'],format='%Y%m%d')\n"
      ],
      "id": "JX7jK4_3LP08"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6-SD3uoMhKH"
      },
      "outputs": [],
      "source": [
        "final_result['clear_date'] = final_result['due_in_date'] + final_result['Avg_Delay']"
      ],
      "id": "c6-SD3uoMhKH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QcX_fAjIkYR"
      },
      "source": [
        "### Display the \"clear_date\" column"
      ],
      "id": "9QcX_fAjIkYR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "740e1486"
      },
      "outputs": [],
      "source": [
        "final_result['clear_date']"
      ],
      "id": "740e1486"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSkNLq6-z7rZ"
      },
      "source": [
        "### Convert the average delay into number of days format \n",
        "\n",
        "- Note - Formula = avg_delay//(24 * 3600)\n",
        "- Note - full code is given for this, no need to change "
      ],
      "id": "MSkNLq6-z7rZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbBBZPjP0W7o"
      },
      "source": [
        "### Display the \"avg_delay\" column "
      ],
      "id": "wbBBZPjP0W7o"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a494982f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "final_result['Avg_Delay']"
      ],
      "id": "a494982f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "815d8811"
      },
      "source": [
        "### Now you need to convert average delay column into bucket\n",
        "\n",
        "- Need to perform binning \n",
        "- create a list of bins i.e. bins= [0,15,30,45,60,100]\n",
        "- create a list of labels i.e. labels = ['0-15','16-30','31-45','46-60','Greatar than 60']\n",
        "- perform binning by using cut() function from \"Final\" dataframe\n",
        "\n",
        "\n",
        "- Please fill up the first two rows of the code"
      ],
      "id": "815d8811"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ok_Mjb6ZPUNu"
      },
      "outputs": [],
      "source": [
        "aging_bucket = []\n",
        "for x in predicted:\n",
        "    if x<=15:\n",
        "        aging_bucket.append(\"0-15days\")\n",
        "    elif x<=30:\n",
        "        aging_bucket.append(\"16-30days\")\n",
        "    elif x<=45:\n",
        "        aging_bucket.append(\"31-45days\")\n",
        "    elif x<=60:\n",
        "        aging_bucket.append(\"46-60days\")\n",
        "    else:\n",
        "        aging_bucket.append(\"Greater than 60 days\")\n",
        "final_result['Aging Bucket']= aging_bucket\n"
      ],
      "id": "Ok_Mjb6ZPUNu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c35725f"
      },
      "source": [
        "### Now you need to drop \"key_0\" and \"avg_delay\" columns from the \"Final\" Dataframe"
      ],
      "id": "1c35725f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b31bc6a3"
      },
      "outputs": [],
      "source": [
        "final.drop(['Avg_Delay'],axis=1,inplace=True)\n"
      ],
      "id": "b31bc6a3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui-tyIvU0-5u"
      },
      "source": [
        "### Display the count of each categoty of new \"Aging Bucket\" column "
      ],
      "id": "Ui-tyIvU0-5u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6e16218"
      },
      "outputs": [],
      "source": [
        "final_result.groupby('Aging Bucket').count()"
      ],
      "id": "a6e16218"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgYegy551GKJ"
      },
      "source": [
        "### Display your final dataset with aging buckets "
      ],
      "id": "kgYegy551GKJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4bc87ec"
      },
      "outputs": [],
      "source": [
        "final_result"
      ],
      "id": "c4bc87ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji7AoDCB1L_x"
      },
      "source": [
        "### Store this dataframe into the .csv format"
      ],
      "id": "Ji7AoDCB1L_x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "727d0b8d"
      },
      "outputs": [],
      "source": [
        "final_result.to_csv('prediction.csv', index=False)"
      ],
      "id": "727d0b8d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK0fabl61SkC"
      },
      "source": [
        "# END OF THE PROJECT"
      ],
      "id": "FK0fabl61SkC"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "62633a84"
      ],
      "name": " Payment date prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}